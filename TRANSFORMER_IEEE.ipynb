{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6yAeJ1DCauWJ",
        "outputId": "7fc77da6-224d-42f7-9a08-a0f4897f4859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fraud detection model training...\n",
            "Data loaded successfully.\n",
            "Train and test datasets merged.\n",
            "Numerical columns downcasted for memory optimization.\n",
            "Train shape after merge and downcast: (7900, 434), Test shape: (5511, 433)\n",
            "Removed 244 columns with >60% missing values.\n",
            "Train shape after dropping high missing cols: (7900, 190), Test shape: (5511, 189)\n",
            "Identified 13 categorical columns and 175 numerical columns.\n",
            "Missing values handled for numerical and categorical columns.\n",
            "Categorical features encoded using LabelEncoder.\n",
            "Engineered 'hour' feature.\n",
            "Log transformed 'TransactionAmt'.\n",
            "Engineered 'card1_freq' feature.\n",
            "Final features selected for model: ['TransactionDT', 'TransactionAmt', 'card1', 'card2', 'card3', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D10', 'D15', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'hour', 'LogTransactionAmt', 'card1_freq', 'M1', 'M3', 'ProductCD', 'addr2', 'M6', 'M4', 'M2', 'card5', 'card6', 'M5', 'addr1', 'card4', 'P_emaildomain']\n",
            "Number of numerical features: 178\n",
            "Number of categorical features: 13\n",
            "Numerical features scaled using StandardScaler.\n",
            "\n",
            "--- Calculating Feature Importance using L1-Regularized Logistic Regression ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1-3043268185.py:139: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train['hour'] = (train['TransactionDT'] // 3600) % 24\n",
            "/tmp/ipython-input-1-3043268185.py:140: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test['hour'] = (test['TransactionDT'] // 3600) % 24\n",
            "/tmp/ipython-input-1-3043268185.py:147: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train['LogTransactionAmt'] = np.log1p(train['TransactionAmt'])\n",
            "/tmp/ipython-input-1-3043268185.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test['LogTransactionAmt'] = np.log1p(test['TransactionAmt'])\n",
            "/tmp/ipython-input-1-3043268185.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train['card1_freq'] = train['card1'].map(freq_map)\n",
            "/tmp/ipython-input-1-3043268185.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test['card1_freq'] = test['card1'].map(freq_map)\n",
            "/tmp/ipython-input-1-3043268185.py:185: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
            "/tmp/ipython-input-1-3043268185.py:186: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_test_full[numerical_cols] = scaler.transform(X_test_full[numerical_cols])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 Feature Importances (by absolute coefficient):\n",
            "          Feature  Coefficient  Absolute_Coefficient\n",
            "            card6    -0.841133              0.841133\n",
            "              C12     0.688827              0.688827\n",
            "        ProductCD    -0.449612              0.449612\n",
            "            addr2    -0.434797              0.434797\n",
            "LogTransactionAmt     0.407318              0.407318\n",
            "              V67     0.278208              0.278208\n",
            "              V83     0.274960              0.274960\n",
            "              V12     0.260302              0.260302\n",
            "            card3     0.259873              0.259873\n",
            "              V20    -0.249863              0.249863\n",
            "             V287     0.191170              0.191170\n",
            "              V70    -0.175225              0.175225\n",
            "       card1_freq    -0.166927              0.166927\n",
            "             V120     0.162879              0.162879\n",
            "              V63    -0.158228              0.158228\n",
            "               C7    -0.156715              0.156715\n",
            "               M4    -0.150241              0.150241\n",
            "             V132    -0.141061              0.141061\n",
            "               M6    -0.140843              0.140843\n",
            "               M5    -0.139735              0.139735\n",
            "--- End Feature Importance ---\n",
            "Applying SMOTE to address class imbalance...\n",
            "Original class distribution: isFraud\n",
            "0    7713\n",
            "1     187\n",
            "Name: count, dtype: int64\n",
            "Resampled class distribution: isFraud\n",
            "0    7713\n",
            "1    7713\n",
            "Name: count, dtype: int64\n",
            "Resampled Train set shape: (10798, 191), Validation set shape: (2314, 191), Test set shape: (2314, 191)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ cat_input_M1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_M3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_ProductCD │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_addr2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_M6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_M4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_M2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_card5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_card6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_M5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_addr1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_card4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_P_emaild… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numerical_input     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m178\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m64\u001b[0m │ cat_input_M1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m96\u001b[0m │ cat_input_M3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_ProductCD │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m160\u001b[0m │ cat_input_Produc… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_addr2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m192\u001b[0m │ cat_input_addr2[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m96\u001b[0m │ cat_input_M6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ cat_input_M4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m96\u001b[0m │ cat_input_M2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_card5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m1,440\u001b[0m │ cat_input_card5[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_card6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m64\u001b[0m │ cat_input_card6[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m96\u001b[0m │ cat_input_M5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_addr1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m2,144\u001b[0m │ cat_input_addr1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_card4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m160\u001b[0m │ cat_input_card4[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_P_emaild… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m1,728\u001b[0m │ cat_input_P_emai… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numerical_projecti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m5,728\u001b[0m │ numerical_input[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_M1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_M3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_Produc… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_addr2[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_M6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_M4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_M2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_card5[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_card6[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_M5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_addr1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_card4[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_P_emai… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ numerical_projec… │\n",
              "│                     │                   │            │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ flatten_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ flatten_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │     \u001b[38;5;34m16,800\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m64\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m4,128\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m64\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │     \u001b[38;5;34m16,800\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m64\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m4,128\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m64\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m8,448\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ cat_input_M1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_M3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_ProductCD │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_addr2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_M6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_M4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_M2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_card5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_card6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_M5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_addr1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_card4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ cat_input_P_emaild… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numerical_input     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ cat_input_M1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ cat_input_M3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_ProductCD │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ cat_input_Produc… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_addr2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ cat_input_addr2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ cat_input_M6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ cat_input_M4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ cat_input_M2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_card5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,440</span> │ cat_input_card5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_card6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ cat_input_card6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_M5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ cat_input_M5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_addr1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ cat_input_addr1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_card4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ cat_input_card4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_P_emaild… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │ cat_input_P_emai… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numerical_projecti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,728</span> │ numerical_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_M1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_M3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_Produc… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_addr2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_M6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_M4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_M2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_card5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_card6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_M5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_addr1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_card4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_P_emai… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ numerical_projec… │\n",
              "│                     │                   │            │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ flatten_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ flatten_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,800</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,800</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,225\u001b[0m (407.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,225</span> (407.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m104,225\u001b[0m (407.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,225</span> (407.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer model built and compiled.\n",
            "\n",
            "--- Training Transformer Model ---\n",
            "Epoch 1/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 942ms/step - accuracy: 0.5831 - auc: 0.6104 - loss: 0.6801 - precision: 0.6019 - recall: 0.4821 - val_accuracy: 0.6845 - val_auc: 0.7740 - val_loss: 0.6445 - val_precision: 0.7423 - val_recall: 0.5653\n",
            "Epoch 2/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 588ms/step - accuracy: 0.6776 - auc: 0.7452 - loss: 0.6404 - precision: 0.6964 - recall: 0.6293 - val_accuracy: 0.7308 - val_auc: 0.8164 - val_loss: 0.5958 - val_precision: 0.7638 - val_recall: 0.6681\n",
            "Epoch 3/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 607ms/step - accuracy: 0.7367 - auc: 0.8089 - loss: 0.5912 - precision: 0.7576 - recall: 0.6939 - val_accuracy: 0.7610 - val_auc: 0.8539 - val_loss: 0.5356 - val_precision: 0.7844 - val_recall: 0.7200\n",
            "Epoch 4/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 708ms/step - accuracy: 0.7804 - auc: 0.8567 - loss: 0.5296 - precision: 0.7888 - recall: 0.7559 - val_accuracy: 0.8094 - val_auc: 0.8935 - val_loss: 0.4630 - val_precision: 0.8108 - val_recall: 0.8073\n",
            "Epoch 5/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 620ms/step - accuracy: 0.8025 - auc: 0.8871 - loss: 0.4679 - precision: 0.8057 - recall: 0.7964 - val_accuracy: 0.8531 - val_auc: 0.9252 - val_loss: 0.3909 - val_precision: 0.8494 - val_recall: 0.8583\n",
            "Epoch 6/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 568ms/step - accuracy: 0.8363 - auc: 0.9132 - loss: 0.4073 - precision: 0.8322 - recall: 0.8447 - val_accuracy: 0.8717 - val_auc: 0.9382 - val_loss: 0.3365 - val_precision: 0.8733 - val_recall: 0.8695\n",
            "Epoch 7/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 644ms/step - accuracy: 0.8529 - auc: 0.9274 - loss: 0.3584 - precision: 0.8519 - recall: 0.8530 - val_accuracy: 0.8863 - val_auc: 0.9477 - val_loss: 0.3013 - val_precision: 0.8782 - val_recall: 0.8971\n",
            "Epoch 8/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 567ms/step - accuracy: 0.8678 - auc: 0.9380 - loss: 0.3243 - precision: 0.8672 - recall: 0.8678 - val_accuracy: 0.8933 - val_auc: 0.9548 - val_loss: 0.2767 - val_precision: 0.8843 - val_recall: 0.9049\n",
            "Epoch 9/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 685ms/step - accuracy: 0.8809 - auc: 0.9493 - loss: 0.2934 - precision: 0.8727 - recall: 0.8923 - val_accuracy: 0.9019 - val_auc: 0.9603 - val_loss: 0.2571 - val_precision: 0.8995 - val_recall: 0.9049\n",
            "Epoch 10/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 566ms/step - accuracy: 0.8890 - auc: 0.9548 - loss: 0.2755 - precision: 0.8812 - recall: 0.8997 - val_accuracy: 0.9071 - val_auc: 0.9644 - val_loss: 0.2428 - val_precision: 0.9026 - val_recall: 0.9127\n",
            "Epoch 11/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 595ms/step - accuracy: 0.8999 - auc: 0.9605 - loss: 0.2560 - precision: 0.8939 - recall: 0.9095 - val_accuracy: 0.9136 - val_auc: 0.9680 - val_loss: 0.2298 - val_precision: 0.9093 - val_recall: 0.9188\n",
            "Epoch 12/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 564ms/step - accuracy: 0.9107 - auc: 0.9657 - loss: 0.2372 - precision: 0.9074 - recall: 0.9151 - val_accuracy: 0.9196 - val_auc: 0.9717 - val_loss: 0.2166 - val_precision: 0.9196 - val_recall: 0.9196\n",
            "Epoch 13/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 578ms/step - accuracy: 0.9113 - auc: 0.9668 - loss: 0.2327 - precision: 0.9067 - recall: 0.9166 - val_accuracy: 0.9252 - val_auc: 0.9740 - val_loss: 0.2061 - val_precision: 0.9155 - val_recall: 0.9369\n",
            "Epoch 14/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 735ms/step - accuracy: 0.9166 - auc: 0.9715 - loss: 0.2159 - precision: 0.9056 - recall: 0.9296 - val_accuracy: 0.9274 - val_auc: 0.9763 - val_loss: 0.1964 - val_precision: 0.9194 - val_recall: 0.9369\n",
            "Epoch 15/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 704ms/step - accuracy: 0.9209 - auc: 0.9738 - loss: 0.2069 - precision: 0.9174 - recall: 0.9262 - val_accuracy: 0.9313 - val_auc: 0.9783 - val_loss: 0.1872 - val_precision: 0.9280 - val_recall: 0.9352\n",
            "Epoch 16/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 570ms/step - accuracy: 0.9239 - auc: 0.9757 - loss: 0.1994 - precision: 0.9253 - recall: 0.9216 - val_accuracy: 0.9382 - val_auc: 0.9805 - val_loss: 0.1770 - val_precision: 0.9363 - val_recall: 0.9404\n",
            "Epoch 17/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 583ms/step - accuracy: 0.9270 - auc: 0.9773 - loss: 0.1902 - precision: 0.9234 - recall: 0.9325 - val_accuracy: 0.9395 - val_auc: 0.9820 - val_loss: 0.1683 - val_precision: 0.9320 - val_recall: 0.9481\n",
            "Epoch 18/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 603ms/step - accuracy: 0.9346 - auc: 0.9809 - loss: 0.1753 - precision: 0.9327 - recall: 0.9367 - val_accuracy: 0.9425 - val_auc: 0.9834 - val_loss: 0.1620 - val_precision: 0.9384 - val_recall: 0.9473\n",
            "Epoch 19/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 642ms/step - accuracy: 0.9387 - auc: 0.9822 - loss: 0.1685 - precision: 0.9347 - recall: 0.9425 - val_accuracy: 0.9417 - val_auc: 0.9848 - val_loss: 0.1545 - val_precision: 0.9338 - val_recall: 0.9507\n",
            "Epoch 20/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 695ms/step - accuracy: 0.9443 - auc: 0.9850 - loss: 0.1546 - precision: 0.9394 - recall: 0.9480 - val_accuracy: 0.9438 - val_auc: 0.9857 - val_loss: 0.1490 - val_precision: 0.9454 - val_recall: 0.9421\n",
            "Epoch 21/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 620ms/step - accuracy: 0.9431 - auc: 0.9846 - loss: 0.1563 - precision: 0.9430 - recall: 0.9439 - val_accuracy: 0.9473 - val_auc: 0.9867 - val_loss: 0.1439 - val_precision: 0.9450 - val_recall: 0.9499\n",
            "Epoch 22/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 576ms/step - accuracy: 0.9480 - auc: 0.9866 - loss: 0.1444 - precision: 0.9476 - recall: 0.9495 - val_accuracy: 0.9490 - val_auc: 0.9879 - val_loss: 0.1374 - val_precision: 0.9513 - val_recall: 0.9464\n",
            "Epoch 23/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 692ms/step - accuracy: 0.9500 - auc: 0.9879 - loss: 0.1392 - precision: 0.9525 - recall: 0.9473 - val_accuracy: 0.9507 - val_auc: 0.9883 - val_loss: 0.1333 - val_precision: 0.9469 - val_recall: 0.9551\n",
            "Epoch 24/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 711ms/step - accuracy: 0.9498 - auc: 0.9881 - loss: 0.1353 - precision: 0.9456 - recall: 0.9544 - val_accuracy: 0.9538 - val_auc: 0.9894 - val_loss: 0.1274 - val_precision: 0.9487 - val_recall: 0.9594\n",
            "Epoch 25/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 569ms/step - accuracy: 0.9509 - auc: 0.9896 - loss: 0.1291 - precision: 0.9458 - recall: 0.9555 - val_accuracy: 0.9572 - val_auc: 0.9897 - val_loss: 0.1259 - val_precision: 0.9537 - val_recall: 0.9611\n",
            "Epoch 26/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 621ms/step - accuracy: 0.9575 - auc: 0.9908 - loss: 0.1171 - precision: 0.9536 - recall: 0.9617 - val_accuracy: 0.9568 - val_auc: 0.9905 - val_loss: 0.1214 - val_precision: 0.9506 - val_recall: 0.9637\n",
            "Epoch 27/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 688ms/step - accuracy: 0.9553 - auc: 0.9915 - loss: 0.1159 - precision: 0.9566 - recall: 0.9538 - val_accuracy: 0.9594 - val_auc: 0.9906 - val_loss: 0.1193 - val_precision: 0.9523 - val_recall: 0.9672\n",
            "Epoch 28/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 609ms/step - accuracy: 0.9590 - auc: 0.9915 - loss: 0.1140 - precision: 0.9507 - recall: 0.9679 - val_accuracy: 0.9607 - val_auc: 0.9910 - val_loss: 0.1163 - val_precision: 0.9548 - val_recall: 0.9672\n",
            "Epoch 29/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 588ms/step - accuracy: 0.9629 - auc: 0.9922 - loss: 0.1071 - precision: 0.9560 - recall: 0.9706 - val_accuracy: 0.9615 - val_auc: 0.9915 - val_loss: 0.1127 - val_precision: 0.9572 - val_recall: 0.9663\n",
            "Epoch 30/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 576ms/step - accuracy: 0.9624 - auc: 0.9921 - loss: 0.1065 - precision: 0.9588 - recall: 0.9663 - val_accuracy: 0.9607 - val_auc: 0.9914 - val_loss: 0.1200 - val_precision: 0.9449 - val_recall: 0.9784\n",
            "Epoch 31/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 697ms/step - accuracy: 0.9630 - auc: 0.9936 - loss: 0.1003 - precision: 0.9537 - recall: 0.9718 - val_accuracy: 0.9641 - val_auc: 0.9916 - val_loss: 0.1093 - val_precision: 0.9559 - val_recall: 0.9732\n",
            "Epoch 32/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 616ms/step - accuracy: 0.9623 - auc: 0.9931 - loss: 0.1018 - precision: 0.9600 - recall: 0.9643 - val_accuracy: 0.9650 - val_auc: 0.9921 - val_loss: 0.1042 - val_precision: 0.9606 - val_recall: 0.9697\n",
            "Epoch 33/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 583ms/step - accuracy: 0.9654 - auc: 0.9943 - loss: 0.0928 - precision: 0.9640 - recall: 0.9669 - val_accuracy: 0.9650 - val_auc: 0.9919 - val_loss: 0.1063 - val_precision: 0.9536 - val_recall: 0.9775\n",
            "Epoch 34/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 699ms/step - accuracy: 0.9677 - auc: 0.9940 - loss: 0.0929 - precision: 0.9616 - recall: 0.9741 - val_accuracy: 0.9646 - val_auc: 0.9925 - val_loss: 0.1028 - val_precision: 0.9606 - val_recall: 0.9689\n",
            "Epoch 35/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 608ms/step - accuracy: 0.9699 - auc: 0.9954 - loss: 0.0832 - precision: 0.9657 - recall: 0.9739 - val_accuracy: 0.9663 - val_auc: 0.9923 - val_loss: 0.1014 - val_precision: 0.9560 - val_recall: 0.9775\n",
            "Epoch 36/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 587ms/step - accuracy: 0.9693 - auc: 0.9949 - loss: 0.0853 - precision: 0.9643 - recall: 0.9744 - val_accuracy: 0.9659 - val_auc: 0.9926 - val_loss: 0.0980 - val_precision: 0.9679 - val_recall: 0.9637\n",
            "Epoch 37/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 577ms/step - accuracy: 0.9712 - auc: 0.9949 - loss: 0.0839 - precision: 0.9705 - recall: 0.9720 - val_accuracy: 0.9667 - val_auc: 0.9932 - val_loss: 0.0956 - val_precision: 0.9696 - val_recall: 0.9637\n",
            "Epoch 38/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 650ms/step - accuracy: 0.9709 - auc: 0.9952 - loss: 0.0811 - precision: 0.9704 - recall: 0.9716 - val_accuracy: 0.9693 - val_auc: 0.9930 - val_loss: 0.0936 - val_precision: 0.9689 - val_recall: 0.9697\n",
            "Epoch 39/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 698ms/step - accuracy: 0.9741 - auc: 0.9946 - loss: 0.0813 - precision: 0.9708 - recall: 0.9779 - val_accuracy: 0.9702 - val_auc: 0.9929 - val_loss: 0.0925 - val_precision: 0.9682 - val_recall: 0.9723\n",
            "Epoch 40/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 608ms/step - accuracy: 0.9728 - auc: 0.9958 - loss: 0.0756 - precision: 0.9698 - recall: 0.9761 - val_accuracy: 0.9706 - val_auc: 0.9926 - val_loss: 0.0931 - val_precision: 0.9650 - val_recall: 0.9767\n",
            "Epoch 41/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 559ms/step - accuracy: 0.9738 - auc: 0.9954 - loss: 0.0794 - precision: 0.9707 - recall: 0.9771 - val_accuracy: 0.9719 - val_auc: 0.9932 - val_loss: 0.0893 - val_precision: 0.9691 - val_recall: 0.9749\n",
            "Epoch 42/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 557ms/step - accuracy: 0.9753 - auc: 0.9959 - loss: 0.0735 - precision: 0.9713 - recall: 0.9798 - val_accuracy: 0.9710 - val_auc: 0.9930 - val_loss: 0.0912 - val_precision: 0.9642 - val_recall: 0.9784\n",
            "Epoch 43/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 682ms/step - accuracy: 0.9777 - auc: 0.9962 - loss: 0.0692 - precision: 0.9738 - recall: 0.9816 - val_accuracy: 0.9719 - val_auc: 0.9931 - val_loss: 0.0896 - val_precision: 0.9675 - val_recall: 0.9767\n",
            "Epoch 44/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 695ms/step - accuracy: 0.9798 - auc: 0.9968 - loss: 0.0628 - precision: 0.9769 - recall: 0.9829 - val_accuracy: 0.9715 - val_auc: 0.9932 - val_loss: 0.0881 - val_precision: 0.9658 - val_recall: 0.9775\n",
            "Epoch 45/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 557ms/step - accuracy: 0.9787 - auc: 0.9966 - loss: 0.0638 - precision: 0.9745 - recall: 0.9828 - val_accuracy: 0.9710 - val_auc: 0.9934 - val_loss: 0.0911 - val_precision: 0.9580 - val_recall: 0.9853\n",
            "Epoch 46/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 688ms/step - accuracy: 0.9777 - auc: 0.9965 - loss: 0.0661 - precision: 0.9748 - recall: 0.9810 - val_accuracy: 0.9706 - val_auc: 0.9937 - val_loss: 0.0867 - val_precision: 0.9722 - val_recall: 0.9689\n",
            "Epoch 47/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 703ms/step - accuracy: 0.9799 - auc: 0.9972 - loss: 0.0602 - precision: 0.9806 - recall: 0.9794 - val_accuracy: 0.9754 - val_auc: 0.9937 - val_loss: 0.0837 - val_precision: 0.9685 - val_recall: 0.9827\n",
            "Epoch 48/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 553ms/step - accuracy: 0.9807 - auc: 0.9969 - loss: 0.0606 - precision: 0.9788 - recall: 0.9825 - val_accuracy: 0.9741 - val_auc: 0.9936 - val_loss: 0.0852 - val_precision: 0.9708 - val_recall: 0.9775\n",
            "Epoch 49/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 589ms/step - accuracy: 0.9828 - auc: 0.9974 - loss: 0.0559 - precision: 0.9809 - recall: 0.9843 - val_accuracy: 0.9749 - val_auc: 0.9938 - val_loss: 0.0816 - val_precision: 0.9733 - val_recall: 0.9767\n",
            "Epoch 50/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 556ms/step - accuracy: 0.9799 - auc: 0.9972 - loss: 0.0585 - precision: 0.9778 - recall: 0.9815 - val_accuracy: 0.9736 - val_auc: 0.9933 - val_loss: 0.0859 - val_precision: 0.9740 - val_recall: 0.9732\n",
            "Transformer model training complete.\n",
            "\n",
            "--- Evaluating on Train Set ---\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step\n",
            "\n",
            "Train Set Performance (Threshold=0.5):\n",
            "Precision: 0.9826\n",
            "Recall (Sensitivity): 0.9828\n",
            "F1 Score: 0.9827\n",
            "AUC: 0.9979\n",
            "Accuracy: 0.9827\n",
            "Specificity: 0.9826\n",
            "G-Mean (Sensitivity-Specificity): 0.9827\n",
            "\n",
            "--- Evaluating on Test Set ---\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\n",
            "Test Set Performance (Threshold=0.5):\n",
            "Precision: 0.9690\n",
            "Recall (Sensitivity): 0.9723\n",
            "F1 Score: 0.9707\n",
            "AUC: 0.9944\n",
            "Accuracy: 0.9706\n",
            "Specificity: 0.9689\n",
            "G-Mean (Sensitivity-Specificity): 0.9706\n",
            "\n",
            "--- Generating Submission File ---\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
            "\n",
            "Submission file 'submission_transformer_model.csv' created successfully!\n",
            "Model training and prediction complete.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import gc\n",
        "\n",
        "print(\"Starting fraud detection model training...\")\n",
        "\n",
        "# Step 1: Load the Data\n",
        "# Ensure these paths are correct for your environment\n",
        "try:\n",
        "    train_identity = pd.read_csv(r'/content/train_identity.csv')\n",
        "    train_transaction = pd.read_csv(r\"/content/train_transaction.csv\")\n",
        "    test_identity = pd.read_csv(r\"/content/test_identity.csv\")\n",
        "    test_transaction = pd.read_csv(r\"/content/test_transaction.csv\")\n",
        "    sample_submission = pd.read_csv(r\"/content/sample_submission.csv\")\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading data: {e}. Please ensure the CSV files are in the specified '/content/' directory.\")\n",
        "    exit() # Exit if data files are not found\n",
        "\n",
        "# Step 1.1: Fix column names in test_identity\n",
        "# This ensures consistency in column names for merging.\n",
        "test_identity.columns = [col.replace('id-', 'id_') for col in test_identity.columns]\n",
        "\n",
        "# Step 1.2: Combine the datasets\n",
        "# Merge transaction and identity data for both train and test sets.\n",
        "# 'left' merge is used to keep all transaction records and add identity info where available.\n",
        "train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
        "test = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\n",
        "print(\"Train and test datasets merged.\")\n",
        "\n",
        "# Step 1.3: Optimize memory by downcasting numerical columns\n",
        "# This function reduces memory usage by converting numerical columns to smaller data types.\n",
        "def downcast_df(df):\n",
        "    for col in df.select_dtypes(include=['int64']).columns:\n",
        "        df[col] = pd.to_numeric(df[col], downcast='integer')\n",
        "    for col in df.select_dtypes(include=['float64']).columns:\n",
        "        df[col] = pd.to_numeric(df[col], downcast='float')\n",
        "    return df\n",
        "\n",
        "train = downcast_df(train)\n",
        "test = downcast_df(test)\n",
        "print(\"Numerical columns downcasted for memory optimization.\")\n",
        "\n",
        "# Store TransactionID for test set alignment later\n",
        "test_ids = test['TransactionID'].copy()\n",
        "\n",
        "# Clean up memory\n",
        "# Explicitly delete original dataframes to free up memory.\n",
        "del train_identity, train_transaction, test_identity, test_transaction\n",
        "gc.collect() # Garbage collection\n",
        "\n",
        "print(f\"Train shape after merge and downcast: {train.shape}, Test shape: {test.shape}\")\n",
        "\n",
        "# Step 2: Preprocessing\n",
        "# 2.1: Remove features with high missing values (>60%)\n",
        "# Columns with more than 60% missing values are typically not very useful and are removed.\n",
        "missing_percent = train.isnull().mean()\n",
        "high_missing_cols = missing_percent[missing_percent > 0.6].index.tolist()\n",
        "# Ensure 'TransactionID' is not accidentally removed if it meets the criteria\n",
        "if 'TransactionID' in high_missing_cols:\n",
        "    high_missing_cols.remove('TransactionID')\n",
        "train.drop(columns=high_missing_cols, inplace=True)\n",
        "test.drop(columns=high_missing_cols, inplace=True)\n",
        "print(f\"Removed {len(high_missing_cols)} columns with >60% missing values.\")\n",
        "print(f\"Train shape after dropping high missing cols: {train.shape}, Test shape: {test.shape}\")\n",
        "\n",
        "\n",
        "# 2.2: Define categorical and numerical columns for processing\n",
        "# Identify columns that are likely categorical or numerical based on their data types and context.\n",
        "# Ensure 'isFraud' and 'TransactionID' are excluded from numerical feature lists as they are target/identifiers.\n",
        "all_cols = set(train.columns)\n",
        "# Explicitly defined categorical columns\n",
        "initial_categorical_cols = ['ProductCD', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain',\n",
        "                            'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n",
        "initial_categorical_cols = [col for col in initial_categorical_cols if col in all_cols]\n",
        "\n",
        "# Identify columns that are objects and not in initial categorical list (potentially more categories or other objects)\n",
        "object_cols = train.select_dtypes(include='object').columns.tolist()\n",
        "additional_categorical_cols = [col for col in object_cols if col not in initial_categorical_cols]\n",
        "# Union of both lists\n",
        "categorical_cols = list(set(initial_categorical_cols + additional_categorical_cols))\n",
        "\n",
        "# Numerical columns: all remaining numeric types, excluding target and ID.\n",
        "numerical_cols = train.select_dtypes(include=['float32', 'float64', 'int8', 'int16', 'int32']).columns.tolist()\n",
        "if 'isFraud' in numerical_cols:\n",
        "    numerical_cols.remove('isFraud')\n",
        "if 'TransactionID' in numerical_cols:\n",
        "    numerical_cols.remove('TransactionID')\n",
        "# Remove any numerical columns that were also identified as categorical (e.g., if LabelEncoder was applied early)\n",
        "numerical_cols = [col for col in numerical_cols if col not in categorical_cols]\n",
        "\n",
        "print(f\"Identified {len(categorical_cols)} categorical columns and {len(numerical_cols)} numerical columns.\")\n",
        "\n",
        "\n",
        "# 2.3: Handle missing values\n",
        "# Impute numerical features with their median and categorical features with 'missing' placeholder.\n",
        "for col in numerical_cols:\n",
        "    train[col] = train[col].fillna(train[col].median())\n",
        "    test[col] = test[col].fillna(test[col].median())\n",
        "    if train[col].isnull().any() or test[col].isnull().any(): # Double check after median fill\n",
        "        print(f\"Warning: Missing values still exist in numerical column {col} after median fill.\")\n",
        "\n",
        "for col in categorical_cols:\n",
        "    train[col] = train[col].fillna('missing').astype(str)\n",
        "    test[col] = test[col].fillna('missing').astype(str)\n",
        "    if train[col].isnull().any() or test[col].isnull().any(): # Double check after 'missing' fill\n",
        "        print(f\"Warning: Missing values still exist in categorical column {col} after 'missing' fill.\")\n",
        "print(\"Missing values handled for numerical and categorical columns.\")\n",
        "\n",
        "\n",
        "# 2.4: Encode categorical features using LabelEncoder\n",
        "# LabelEncoder converts categorical text data into numerical labels, suitable for embeddings.\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    # Combine train and test data for fitting to ensure consistent encoding across both datasets.\n",
        "    combined = pd.concat([train[col], test[col]], axis=0)\n",
        "    le.fit(combined.astype(str)) # Fit on string type\n",
        "    train[col] = le.transform(train[col].astype(str))\n",
        "    test[col] = le.transform(test[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "    # Store the number of unique classes for embedding layer dimensions\n",
        "    # +1 for 'missing' or any new unseen categories if applicable, though LabelEncoder handles this by assigning largest int.\n",
        "    train[col] = train[col].astype(int)\n",
        "    test[col] = test[col].astype(int)\n",
        "print(\"Categorical features encoded using LabelEncoder.\")\n",
        "\n",
        "# Step 3: Feature Engineering\n",
        "# 3.1: Time-based feature\n",
        "# Extract 'hour' from 'TransactionDT' for potential daily patterns.\n",
        "train['hour'] = (train['TransactionDT'] // 3600) % 24\n",
        "test['hour'] = (test['TransactionDT'] // 3600) % 24\n",
        "numerical_cols.append('hour') # Add 'hour' to numerical features\n",
        "print(\"Engineered 'hour' feature.\")\n",
        "\n",
        "\n",
        "# 3.2: Log transform TransactionAmt\n",
        "# Apply log transformation to TransactionAmt to reduce skewness and handle large ranges.\n",
        "train['LogTransactionAmt'] = np.log1p(train['TransactionAmt'])\n",
        "test['LogTransactionAmt'] = np.log1p(test['TransactionAmt'])\n",
        "numerical_cols.append('LogTransactionAmt') # Add 'LogTransactionAmt' to numerical features\n",
        "print(\"Log transformed 'TransactionAmt'.\")\n",
        "\n",
        "\n",
        "# 3.3: Transaction frequency for card1\n",
        "# Create a frequency-based feature for 'card1' (a common card identifier).\n",
        "if 'card1' in train.columns:\n",
        "    freq_map = train['card1'].value_counts().to_dict()\n",
        "    train['card1_freq'] = train['card1'].map(freq_map)\n",
        "    test['card1_freq'] = test['card1'].map(freq_map)\n",
        "    # Fill NaN values (for card1 values present in test but not train) with 0 frequency.\n",
        "    train['card1_freq'] = train['card1_freq'].fillna(0).astype(int)\n",
        "    test['card1_freq'] = test['card1_freq'].fillna(0).astype(int)\n",
        "    numerical_cols.append('card1_freq') # Add 'card1_freq' to numerical features\n",
        "    print(\"Engineered 'card1_freq' feature.\")\n",
        "\n",
        "\n",
        "# Ensure the final numerical_cols and categorical_cols lists contain only columns that exist in the dataframe\n",
        "numerical_cols = [col for col in numerical_cols if col in train.columns and col not in ['TransactionID', 'isFraud']]\n",
        "categorical_cols = [col for col in categorical_cols if col in train.columns and col not in ['TransactionID', 'isFraud']]\n",
        "\n",
        "# Step 4: Feature Preparation for Transformer\n",
        "# 4.1: Define feature set for the model\n",
        "# The feature set consists of all identified numerical and categorical columns.\n",
        "features = numerical_cols + categorical_cols\n",
        "X = train[features]\n",
        "y = train['isFraud']\n",
        "X_test_full = test[features] # The full test set for final predictions\n",
        "\n",
        "print(f\"Final features selected for model: {features}\")\n",
        "print(f\"Number of numerical features: {len(numerical_cols)}\")\n",
        "print(f\"Number of categorical features: {len(categorical_cols)}\")\n",
        "\n",
        "# 4.2: Scale numerical features\n",
        "# Standardize numerical features to have zero mean and unit variance. This is crucial for models like Transformers.\n",
        "scaler = StandardScaler()\n",
        "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
        "X_test_full[numerical_cols] = scaler.transform(X_test_full[numerical_cols])\n",
        "print(\"Numerical features scaled using StandardScaler.\")\n",
        "\n",
        "# Step 4.5: Feature Importance with L1-Regularized Logistic Regression\n",
        "# L1 regularization (Lasso) can drive less important feature coefficients to zero, aiding in feature selection and importance.\n",
        "print(\"\\n--- Calculating Feature Importance using L1-Regularized Logistic Regression ---\")\n",
        "# Use a copy of X for Logistic Regression to avoid SettingWithCopyWarning\n",
        "X_l1_reg = X.copy()\n",
        "log_reg_l1 = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, C=0.1) # C is inverse of regularization strength\n",
        "log_reg_l1.fit(X_l1_reg, y)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Coefficient': log_reg_l1.coef_[0]\n",
        "})\n",
        "feature_importance['Absolute_Coefficient'] = np.abs(feature_importance['Coefficient'])\n",
        "feature_importance = feature_importance.sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "print(\"Top 20 Feature Importances (by absolute coefficient):\")\n",
        "print(feature_importance.head(20).to_string(index=False))\n",
        "print(\"--- End Feature Importance ---\")\n",
        "\n",
        "\n",
        "# 4.3: SMOTE for handling class imbalance\n",
        "# SMOTE (Synthetic Minority Over-sampling Technique) creates synthetic samples of the minority class.\n",
        "# This helps prevent the model from being biased towards the majority class.\n",
        "print(\"Applying SMOTE to address class imbalance...\")\n",
        "smote = SMOTE(random_state=42, sampling_strategy=1.0) # Full oversampling to balance classes\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "print(f\"Original class distribution: {y.value_counts()}\")\n",
        "print(f\"Resampled class distribution: {y_resampled.value_counts()}\")\n",
        "\n",
        "# 4.4: Create train/val/test split (70/15/15)\n",
        "# Split the resampled data into training, validation, and test sets.\n",
        "# Validation set is used for monitoring training performance and early stopping.\n",
        "X_train_resampled, X_temp_resampled, y_train_resampled, y_temp_resampled = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled\n",
        ")\n",
        "X_val_resampled, X_test_resampled, y_val_resampled, y_test_resampled = train_test_split(\n",
        "    X_temp_resampled, y_temp_resampled, test_size=0.5, random_state=42, stratify=y_temp_resampled\n",
        ")\n",
        "\n",
        "print(f\"Resampled Train set shape: {X_train_resampled.shape}, Validation set shape: {X_val_resampled.shape}, Test set shape: {X_test_resampled.shape}\")\n",
        "\n",
        "# Prepare inputs for TensorFlow model (convert to numpy arrays of appropriate type)\n",
        "X_train_num = X_train_resampled[numerical_cols].values.astype(np.float32)\n",
        "X_val_num = X_val_resampled[numerical_cols].values.astype(np.float32)\n",
        "X_test_num = X_test_resampled[numerical_cols].values.astype(np.float32)\n",
        "X_test_full_num = X_test_full[numerical_cols].values.astype(np.float32)\n",
        "\n",
        "\n",
        "# Step 5: Build Transformer Model\n",
        "# This section defines the Transformer architecture for tabular data.\n",
        "# It uses embedding layers for categorical features and combines them with numerical features.\n",
        "# A custom Transformer block is defined for multi-head self-attention.\n",
        "\n",
        "def create_transformer_model(\n",
        "    num_numerical_features,\n",
        "    categorical_features_info, # List of (col_name, num_unique_values) for embeddings\n",
        "    embedding_dim=32,\n",
        "    num_heads=4,\n",
        "    ff_dim=128,\n",
        "    num_transformer_blocks=2,\n",
        "    mlp_units=[256, 128],\n",
        "    dropout_rate=0.2\n",
        "):\n",
        "    # Input for numerical features\n",
        "    numerical_input = keras.Input(shape=(num_numerical_features,), name=\"numerical_input\")\n",
        "    numerical_features = numerical_input\n",
        "\n",
        "    # Inputs for categorical features and their embeddings\n",
        "    categorical_inputs = [] # This will hold the Keras Input layers for the model's inputs\n",
        "    all_feature_embeddings_for_stack = [] # This will hold the flattened embedding tensors for stacking\n",
        "\n",
        "    # Add numerical feature projection to the list of features for stacking\n",
        "    numerical_feature_projected = layers.Dense(embedding_dim, activation='relu', name=\"numerical_projection\")(numerical_input)\n",
        "    all_feature_embeddings_for_stack.append(numerical_feature_projected)\n",
        "\n",
        "    # Process categorical features: create input, embedding, and add to lists\n",
        "    for col_name, num_unique_values in categorical_features_info:\n",
        "        cat_input = keras.Input(shape=(1,), name=f\"cat_input_{col_name}\", dtype=tf.int32)\n",
        "        categorical_inputs.append(cat_input) # Add to the list of model inputs\n",
        "\n",
        "        embedding = layers.Embedding(\n",
        "            input_dim=num_unique_values, # Corrected: Use the exact number of unique classes from LabelEncoder\n",
        "            output_dim=embedding_dim,\n",
        "            name=f\"embedding_{col_name}\"\n",
        "        )(cat_input)\n",
        "        all_feature_embeddings_for_stack.append(layers.Flatten()(embedding)) # Add flattened embedding to list for stacking\n",
        "\n",
        "    # Stack all projected features (numerical and categorical embeddings) to create a \"sequence\" for the transformer.\n",
        "    # Shape: (batch_size, num_features, embedding_dim)\n",
        "    transformer_input = layers.Lambda(lambda x: tf.stack(x, axis=1))(all_feature_embeddings_for_stack)\n",
        "\n",
        "    # Add positional embeddings (learned)\n",
        "    num_tokens = 1 + len(categorical_features_info) # Numerical features treated as one token, plus one for each categorical\n",
        "    positional_embedding_layer = layers.Embedding(num_tokens, embedding_dim)\n",
        "    positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
        "    positional_embeddings = positional_embedding_layer(positions)\n",
        "    x = transformer_input + positional_embeddings # Add positional embeddings to input features\n",
        "\n",
        "    # Transformer Blocks\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        # Multi-Head Attention\n",
        "        attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(x, x)\n",
        "        attn_output = layers.Dropout(dropout_rate)(attn_output)\n",
        "        attn_output = layers.LayerNormalization(epsilon=1e-6)(x + attn_output) # Add & Norm\n",
        "\n",
        "        # Feed-Forward Network\n",
        "        ffn_output = layers.Dense(ff_dim, activation=\"relu\")(attn_output)\n",
        "        ffn_output = layers.Dense(embedding_dim)(ffn_output) # Project back to embedding_dim\n",
        "        ffn_output = layers.Dropout(dropout_rate)(ffn_output)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(attn_output + ffn_output) # Add & Norm\n",
        "\n",
        "    # Global Average Pooling or Flatten for classification head\n",
        "    x = layers.GlobalAveragePooling1D()(x) # Shape: (batch_size, embedding_dim)\n",
        "\n",
        "    # MLP for classification\n",
        "    for units in mlp_units:\n",
        "        x = layers.Dense(units, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Output layer\n",
        "    output = layers.Dense(1, activation=\"sigmoid\", name=\"output\")(x)\n",
        "\n",
        "    # Define the model with all inputs\n",
        "    model = keras.Model(inputs=[numerical_input] + categorical_inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Prepare categorical feature info for model creation\n",
        "categorical_features_info = []\n",
        "for col in categorical_cols:\n",
        "    # IMPORTANT FIX: Use len(le.classes_) to get the exact number of unique categories\n",
        "    # that the LabelEncoder was fitted on, ensuring correct input_dim for Embedding.\n",
        "    num_unique_values = len(label_encoders[col].classes_)\n",
        "    categorical_features_info.append((col, num_unique_values))\n",
        "\n",
        "\n",
        "# Instantiate and compile the Transformer model\n",
        "num_numerical_features = len(numerical_cols)\n",
        "transformer_model = create_transformer_model(\n",
        "    num_numerical_features=num_numerical_features,\n",
        "    categorical_features_info=categorical_features_info\n",
        ")\n",
        "\n",
        "transformer_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\n",
        "        keras.metrics.Precision(name='precision'),\n",
        "        keras.metrics.Recall(name='recall'),\n",
        "        keras.metrics.AUC(name='auc'),\n",
        "        'accuracy'\n",
        "    ]\n",
        ")\n",
        "\n",
        "transformer_model.summary()\n",
        "print(\"Transformer model built and compiled.\")\n",
        "\n",
        "# Prepare data for model training (list of arrays for inputs)\n",
        "# Categorical features need to be passed as separate inputs for embedding layers\n",
        "# Ensure each categorical input array has shape (batch_size, 1) to match keras.Input(shape=(1,))\n",
        "X_train_cat = [X_train_resampled[col].values.astype(np.int32).reshape(-1, 1) for col in categorical_cols]\n",
        "X_val_cat = [X_val_resampled[col].values.astype(np.int32).reshape(-1, 1) for col in categorical_cols]\n",
        "X_test_cat = [X_test_resampled[col].values.astype(np.int32).reshape(-1, 1) for col in categorical_cols]\n",
        "X_test_full_cat = [X_test_full[col].values.astype(np.int32).reshape(-1, 1) for col in categorical_cols]\n",
        "\n",
        "train_inputs = [X_train_num] + X_train_cat\n",
        "val_inputs = [X_val_num] + X_val_cat\n",
        "test_inputs = [X_test_num] + X_test_cat\n",
        "full_test_inputs = [X_test_full_num] + X_test_full_cat\n",
        "\n",
        "\n",
        "# Step 6: Train Transformer Model\n",
        "print(\"\\n--- Training Transformer Model ---\")\n",
        "# Use early stopping to prevent overfitting\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_auc',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    mode='max'\n",
        ")\n",
        "\n",
        "history = transformer_model.fit(\n",
        "    train_inputs,\n",
        "    y_train_resampled,\n",
        "    validation_data=(val_inputs, y_val_resampled),\n",
        "    epochs=50, # Set a reasonably high number, early stopping will manage\n",
        "    batch_size=1024,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Transformer model training complete.\")\n",
        "\n",
        "# Step 7: Evaluate on Test Set and Train Set\n",
        "# Function to calculate all required metrics including G-mean\n",
        "def calculate_metrics(y_true, y_pred_probs, threshold=0.5, name=\"\"):\n",
        "    y_pred = (y_pred_probs >= threshold).astype(int)\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_pred_probs)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Calculate Sensitivity (Recall) and Specificity\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    g_mean = np.sqrt(sensitivity * specificity)\n",
        "\n",
        "    print(f\"\\n{name} Set Performance (Threshold={threshold}):\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Specificity: {specificity:.4f}\")\n",
        "    print(f\"G-Mean (Sensitivity-Specificity): {g_mean:.4f}\")\n",
        "    return precision, recall, f1, auc, accuracy, specificity, g_mean\n",
        "\n",
        "\n",
        "# Evaluate on Train Set\n",
        "print(\"\\n--- Evaluating on Train Set ---\")\n",
        "train_probs = transformer_model.predict(train_inputs).flatten()\n",
        "train_metrics = calculate_metrics(y_train_resampled, train_probs, name=\"Train\")\n",
        "\n",
        "# Evaluate on Test Set\n",
        "print(\"\\n--- Evaluating on Test Set ---\")\n",
        "test_probs = transformer_model.predict(test_inputs).flatten()\n",
        "test_metrics = calculate_metrics(y_test_resampled, test_probs, name=\"Test\")\n",
        "\n",
        "# Step 8: Generate Predictions for Submission\n",
        "print(\"\\n--- Generating Submission File ---\")\n",
        "# Predict probabilities on the original, un-split test data\n",
        "test_full_probs = transformer_model.predict(full_test_inputs).flatten()\n",
        "\n",
        "# Create a DataFrame with TransactionID and predictions\n",
        "test_pred_df = pd.DataFrame({\n",
        "    'TransactionID': test_ids,\n",
        "    'isFraud': test_full_probs\n",
        "})\n",
        "\n",
        "# Merge with sample_submission to align predictions\n",
        "# Fill any missing TransactionIDs from sample_submission that might not be in our test_pred_df\n",
        "# (though with left merge and copying test_ids, this should be minimal).\n",
        "# Use mean if any prediction is missing, though probabilities should always be generated.\n",
        "sample_submission = sample_submission.merge(test_pred_df, on='TransactionID', how='left', suffixes=('', '_pred'))\n",
        "sample_submission['isFraud'] = sample_submission['isFraud_pred'].fillna(test_full_probs.mean()) # Fallback\n",
        "sample_submission = sample_submission[['TransactionID', 'isFraud']]\n",
        "\n",
        "# Save submission file\n",
        "submission_filename = 'submission_transformer_model.csv'\n",
        "sample_submission.to_csv(submission_filename, index=False)\n",
        "print(f\"\\nSubmission file '{submission_filename}' created successfully!\")\n",
        "print(\"Model training and prediction complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KdL1eiGeb4h8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}